{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)] on win32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to E:\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from gensim.utils import simple_preprocess\n",
    "from utils import load_data\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "print('Python %s on %s' % (sys.version, sys.platform))\n",
    "sys.path.extend(['E:\\\\LDA_Abstract_README', 'E:/LDA_Abstract_README'])\n",
    "\n",
    "n_topics = [10, 20, 27, 30]\n",
    "\n",
    "\n",
    "textPre_FilePath = \"../data/readme_corpus.txt\"\n",
    "lda_ModelPath = \"./readme_model/\"\n",
    "\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield gensim.utils.simple_preprocess(str(sentence), deacc=True)  # deacc=True removes punctuations\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, notAllowed_postags=None):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    if notAllowed_postags is None:\n",
    "        notAllowed_postags = ['ADJ', 'ADV']\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ not in notAllowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "data = load_data(textPre_FilePath)[351:361]\n",
    "data_words = list(sent_to_words(data))\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# NLTK Stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, notAllowed_postags=['ADJ', 'ADV'])\n",
    "\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# tfidf_model = TfidfModel(corpus)\n",
    "# corpus = tfidf_model[corpus]\n",
    "\n",
    "models = []\n",
    "for n_t in n_topics:\n",
    "    lda = LdaModel.load(lda_ModelPath+'lda_readme'+str(n_t))\n",
    "    models.append(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[phyre, flownet, tenni, censu, plate, breast, ...</td>\n",
       "      <td>[mot, lightgbm, mathematica, sde, kalman, micr...</td>\n",
       "      <td>[googl, research, git, clone, trunk_subdir, fo...</td>\n",
       "      <td>[leakag, banana_banana, gqa, coreset, superres...</td>\n",
       "      <td>[readm, huggingfac, co, md, transform, timm, m...</td>\n",
       "      <td>[darknet, yolov, cfg, yolo, exe_detector, drop...</td>\n",
       "      <td>[mmlab_mmselfsup, heroku, nuscen, mmselfsup, j...</td>\n",
       "      <td>[garden, badg_furi, amr, rashwan_le, powershel...</td>\n",
       "      <td>[model, imag, train, py, pdf, network, dataset...</td>\n",
       "      <td>[probreg, superpixel, udac_drlnd, sage, univer...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[starcraft_ii, pinn, eeg, orbit, pymarl, mcmc,...</td>\n",
       "      <td>[ssd, cascad, capsul, retinanet, fco, nuscen, ...</td>\n",
       "      <td>[check_mark, drug, catalyst, imgur, poetri, gr...</td>\n",
       "      <td>[imag, model, train, pdf, network, py, dataset...</td>\n",
       "      <td>[celeba, triplet, gcn, jindongwang, safeti, op...</td>\n",
       "      <td>[salient, rss, hallucin, superpixel, barycent,...</td>\n",
       "      <td>[garden, tf, tensorflow, model, badg_furi, mml...</td>\n",
       "      <td>[diffus, pointnet, modelnet, gene, lesion, cod...</td>\n",
       "      <td>[bnn, plant, clevr, snli, ape, espnet, gestur,...</td>\n",
       "      <td>[cutout, lightgbm, grad_cam, dart, ode, csi, m...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[imit, forecast, extractor, starcraft_ii, cs_s...</td>\n",
       "      <td>[pointnet, hair, charlesq_pointnet, multifit, ...</td>\n",
       "      <td>[client, trade, pneumonia, voc, disea, wandb, ...</td>\n",
       "      <td>[imag, model, train, pdf, network, py, dataset...</td>\n",
       "      <td>[huggingfac, co, transform, doc, transport, fa...</td>\n",
       "      <td>[physionet, fco, notion, exercis, emnist, scal...</td>\n",
       "      <td>[tweet, defens, cascad, scannet, fl, plant, dy...</td>\n",
       "      <td>[microscopi, srd, ivrl, fluoresc_microscopi, v...</td>\n",
       "      <td>[torchvis, check_mark, forc, capsul, likelihoo...</td>\n",
       "      <td>[mmlab_mmselfsup, crowd, mmselfsup, merlin, pa...</td>\n",
       "      <td>...</td>\n",
       "      <td>[sar, eng, superresolut, udac_drlnd, tednet, m...</td>\n",
       "      <td>[readm, md, diffus, distil, market, xformer, k...</td>\n",
       "      <td>[gh_reagent, circleci, meme, codecov, signatur...</td>\n",
       "      <td>[cgan, stereo, imput, voxceleb, vizdoom, ode, ...</td>\n",
       "      <td>[mtl, bandit, grad_cam, poetri, inject, greedi...</td>\n",
       "      <td>[breast_cancer, shufflenet, advertis, gestur, ...</td>\n",
       "      <td>[moco, fpn, storag_googleapi, maskrcnn_benchma...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[pointnet, modelnet, scannet, voxel, shapenet,...</td>\n",
       "      <td>[yelp, poetri, fsrcnn, elasticsearch, muhammad...</td>\n",
       "      <td>[drug, dynet, tt, mathematica, xai, gpflow_gpf...</td>\n",
       "      <td>[dblp, kornia, pneumonia, alt, disea, manipul,...</td>\n",
       "      <td>[wavenet, signatur, kd, ssl, phyre, coreset, m...</td>\n",
       "      <td>[particl, mtl, occlus, mcd, fiber, davi, appl_...</td>\n",
       "      <td>[dna, homographi, piano, extractor, imbal, wri...</td>\n",
       "      <td>[mesh, heroku, squeez_excit, hallucin, aw, imp...</td>\n",
       "      <td>[check_mark, codecog_latex, chess, linemod, es...</td>\n",
       "      <td>[carla, selector, cs_vmnih, foreground, tagger...</td>\n",
       "      <td>...</td>\n",
       "      <td>[client, wasserstein, expans, hrnet, salient, ...</td>\n",
       "      <td>[sentiment, gin, dgl, forecast, hrnet_hrnet, s...</td>\n",
       "      <td>[brat, tumor, brain_tumor, dice, slice, ship, ...</td>\n",
       "      <td>[imag, model, train, pdf, network, py, dataset...</td>\n",
       "      <td>[grad_cam, gat, breast_cancer, patent, probreg...</td>\n",
       "      <td>[gym, replay, mmlab_mmselfsup, dqn, trial, snn...</td>\n",
       "      <td>[ode, shufflenet, bertmodel, cocotalk, soccer,...</td>\n",
       "      <td>[tg_salt, smile, salt, ga, film, corenlp, frag...</td>\n",
       "      <td>[mxnet, jindongwang, gene, uniti, ffhq, cpn, s...</td>\n",
       "      <td>[garden, tf, model, tensorflow, badg_furi, pac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0   \\\n",
       "0  [phyre, flownet, tenni, censu, plate, breast, ...   \n",
       "1  [starcraft_ii, pinn, eeg, orbit, pymarl, mcmc,...   \n",
       "2  [imit, forecast, extractor, starcraft_ii, cs_s...   \n",
       "3  [pointnet, modelnet, scannet, voxel, shapenet,...   \n",
       "\n",
       "                                                  1   \\\n",
       "0  [mot, lightgbm, mathematica, sde, kalman, micr...   \n",
       "1  [ssd, cascad, capsul, retinanet, fco, nuscen, ...   \n",
       "2  [pointnet, hair, charlesq_pointnet, multifit, ...   \n",
       "3  [yelp, poetri, fsrcnn, elasticsearch, muhammad...   \n",
       "\n",
       "                                                  2   \\\n",
       "0  [googl, research, git, clone, trunk_subdir, fo...   \n",
       "1  [check_mark, drug, catalyst, imgur, poetri, gr...   \n",
       "2  [client, trade, pneumonia, voc, disea, wandb, ...   \n",
       "3  [drug, dynet, tt, mathematica, xai, gpflow_gpf...   \n",
       "\n",
       "                                                  3   \\\n",
       "0  [leakag, banana_banana, gqa, coreset, superres...   \n",
       "1  [imag, model, train, pdf, network, py, dataset...   \n",
       "2  [imag, model, train, pdf, network, py, dataset...   \n",
       "3  [dblp, kornia, pneumonia, alt, disea, manipul,...   \n",
       "\n",
       "                                                  4   \\\n",
       "0  [readm, huggingfac, co, md, transform, timm, m...   \n",
       "1  [celeba, triplet, gcn, jindongwang, safeti, op...   \n",
       "2  [huggingfac, co, transform, doc, transport, fa...   \n",
       "3  [wavenet, signatur, kd, ssl, phyre, coreset, m...   \n",
       "\n",
       "                                                  5   \\\n",
       "0  [darknet, yolov, cfg, yolo, exe_detector, drop...   \n",
       "1  [salient, rss, hallucin, superpixel, barycent,...   \n",
       "2  [physionet, fco, notion, exercis, emnist, scal...   \n",
       "3  [particl, mtl, occlus, mcd, fiber, davi, appl_...   \n",
       "\n",
       "                                                  6   \\\n",
       "0  [mmlab_mmselfsup, heroku, nuscen, mmselfsup, j...   \n",
       "1  [garden, tf, tensorflow, model, badg_furi, mml...   \n",
       "2  [tweet, defens, cascad, scannet, fl, plant, dy...   \n",
       "3  [dna, homographi, piano, extractor, imbal, wri...   \n",
       "\n",
       "                                                  7   \\\n",
       "0  [garden, badg_furi, amr, rashwan_le, powershel...   \n",
       "1  [diffus, pointnet, modelnet, gene, lesion, cod...   \n",
       "2  [microscopi, srd, ivrl, fluoresc_microscopi, v...   \n",
       "3  [mesh, heroku, squeez_excit, hallucin, aw, imp...   \n",
       "\n",
       "                                                  8   \\\n",
       "0  [model, imag, train, py, pdf, network, dataset...   \n",
       "1  [bnn, plant, clevr, snli, ape, espnet, gestur,...   \n",
       "2  [torchvis, check_mark, forc, capsul, likelihoo...   \n",
       "3  [check_mark, codecog_latex, chess, linemod, es...   \n",
       "\n",
       "                                                  9   ...  \\\n",
       "0  [probreg, superpixel, udac_drlnd, sage, univer...  ...   \n",
       "1  [cutout, lightgbm, grad_cam, dart, ode, csi, m...  ...   \n",
       "2  [mmlab_mmselfsup, crowd, mmselfsup, merlin, pa...  ...   \n",
       "3  [carla, selector, cs_vmnih, foreground, tagger...  ...   \n",
       "\n",
       "                                                  20  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  [sar, eng, superresolut, udac_drlnd, tednet, m...   \n",
       "3  [client, wasserstein, expans, hrnet, salient, ...   \n",
       "\n",
       "                                                  21  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  [readm, md, diffus, distil, market, xformer, k...   \n",
       "3  [sentiment, gin, dgl, forecast, hrnet_hrnet, s...   \n",
       "\n",
       "                                                  22  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  [gh_reagent, circleci, meme, codecov, signatur...   \n",
       "3  [brat, tumor, brain_tumor, dice, slice, ship, ...   \n",
       "\n",
       "                                                  23  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  [cgan, stereo, imput, voxceleb, vizdoom, ode, ...   \n",
       "3  [imag, model, train, pdf, network, py, dataset...   \n",
       "\n",
       "                                                  24  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  [mtl, bandit, grad_cam, poetri, inject, greedi...   \n",
       "3  [grad_cam, gat, breast_cancer, patent, probreg...   \n",
       "\n",
       "                                                  25  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  [breast_cancer, shufflenet, advertis, gestur, ...   \n",
       "3  [gym, replay, mmlab_mmselfsup, dqn, trial, snn...   \n",
       "\n",
       "                                                  26  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2  [moco, fpn, storag_googleapi, maskrcnn_benchma...   \n",
       "3  [ode, shufflenet, bertmodel, cocotalk, soccer,...   \n",
       "\n",
       "                                                  27  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  [tg_salt, smile, salt, ga, film, corenlp, frag...   \n",
       "\n",
       "                                                  28  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  [mxnet, jindongwang, gene, uniti, ffhq, cpn, s...   \n",
       "\n",
       "                                                  29  \n",
       "0                                               None  \n",
       "1                                               None  \n",
       "2                                               None  \n",
       "3  [garden, tf, model, tensorflow, badg_furi, pac...  \n",
       "\n",
       "[4 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Print the Keyword in the 10 topics\n",
    "import pandas as pd\n",
    "model_outputs = []\n",
    "for model in models:\n",
    "    model_outputs.append(model.print_topics(num_topics=30, num_words=10))\n",
    "\n",
    "models_topics = []\n",
    "pattern = r'\"(.*?)\"'\n",
    "for output in model_outputs:\n",
    "    models_topics.append([])\n",
    "    for topics in output:\n",
    "        words = re.findall(pattern, topics[1])\n",
    "        models_topics[-1].append(words)\n",
    "pd.DataFrame(models_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>README 1</th>\n",
       "      <th>README 2</th>\n",
       "      <th>README 3</th>\n",
       "      <th>README 4</th>\n",
       "      <th>README 5</th>\n",
       "      <th>README 6</th>\n",
       "      <th>README 7</th>\n",
       "      <th>README 8</th>\n",
       "      <th>README 9</th>\n",
       "      <th>README 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10 Topics</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[doc]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[doc]</td>\n",
       "      <td>[doc, md, transform]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20 Topics</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[datum]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[model, pdf]</td>\n",
       "      <td>[datum]</td>\n",
       "      <td>[model, pdf]</td>\n",
       "      <td>[model, network, train, pdf, py]</td>\n",
       "      <td>[dataset, datum, model, network, test, train, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27 Topics</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[datum]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[model, pdf]</td>\n",
       "      <td>[datum]</td>\n",
       "      <td>[model, pdf]</td>\n",
       "      <td>[model, network, train, pdf, py]</td>\n",
       "      <td>[dataset, datum, model, network, test, train, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30 Topics</th>\n",
       "      <td>[dataset, datum, model, network, test, train]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[dataset, datum, model, network, test, train]</td>\n",
       "      <td>[datum]</td>\n",
       "      <td>[dataset, datum, model, network, test, train]</td>\n",
       "      <td>[model, pdf]</td>\n",
       "      <td>[datum]</td>\n",
       "      <td>[model, pdf]</td>\n",
       "      <td>[model, network, train, pdf, py]</td>\n",
       "      <td>[dataset, datum, model, network, test, train, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                README 1 README 2  \\\n",
       "10 Topics                                             []       []   \n",
       "20 Topics                                             []       []   \n",
       "27 Topics                                             []       []   \n",
       "30 Topics  [dataset, datum, model, network, test, train]       []   \n",
       "\n",
       "                                                README 3 README 4  \\\n",
       "10 Topics                                             []    [doc]   \n",
       "20 Topics                                             []  [datum]   \n",
       "27 Topics                                             []  [datum]   \n",
       "30 Topics  [dataset, datum, model, network, test, train]  [datum]   \n",
       "\n",
       "                                                README 5      README 6  \\\n",
       "10 Topics                                             []            []   \n",
       "20 Topics                                             []  [model, pdf]   \n",
       "27 Topics                                             []  [model, pdf]   \n",
       "30 Topics  [dataset, datum, model, network, test, train]  [model, pdf]   \n",
       "\n",
       "          README 7      README 8                          README 9  \\\n",
       "10 Topics       []            []                             [doc]   \n",
       "20 Topics  [datum]  [model, pdf]  [model, network, train, pdf, py]   \n",
       "27 Topics  [datum]  [model, pdf]  [model, network, train, pdf, py]   \n",
       "30 Topics  [datum]  [model, pdf]  [model, network, train, pdf, py]   \n",
       "\n",
       "                                                   README 10  \n",
       "10 Topics                               [doc, md, transform]  \n",
       "20 Topics  [dataset, datum, model, network, test, train, ...  \n",
       "27 Topics  [dataset, datum, model, network, test, train, ...  \n",
       "30 Topics  [dataset, datum, model, network, test, train, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topics = []\n",
    "for i, model in enumerate(models):\n",
    "    topics_dis = []\n",
    "    for doc in corpus:\n",
    "        model_words = models_topics[i]\n",
    "        topic_idx = max(model.get_document_topics(doc), key=lambda item: item[1])[0]\n",
    "        model_words = model_words[topic_idx]\n",
    "        topics = []\n",
    "        doc_words = [id2word[word_id] for word_id, _ in doc]\n",
    "        for doc_word in doc_words:\n",
    "            for model_word in model_words:\n",
    "                if model_word == doc_word:\n",
    "                    topics.append(model_word)\n",
    "        topics_dis.append(topics)\n",
    "    doc_topics.append(topics_dis)\n",
    "\n",
    "model_doc_topic = pd.DataFrame(doc_topics)\n",
    "model_doc_topic.index = [\"10 Topics\", \"20 Topics\", \"27 Topics\", \"30 Topics\"]\n",
    "columns = []\n",
    "for i in range(10):\n",
    "    columns.append(\"README \" + str(i+1))\n",
    "model_doc_topic.columns = columns\n",
    "model_doc_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}